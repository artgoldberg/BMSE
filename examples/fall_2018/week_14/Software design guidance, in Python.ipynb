{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software design guidance, in Python\n",
    "\n",
    "**[Arthur Goldberg](https://www.mountsinai.org/profiles/arthur-p-goldberg)**\n",
    "\n",
    "This notebook was created for the [Biomedical Software Engineering](https://learn.mssm.edu/webapps/blackboard/content/listContentEditable.jsp?content_id=_448512_1&course_id=_5776_1 \"Biomedical Software Engineering Blackboard site\") course at the [Mount Sinai School of Medicine](https://icahn.mssm.edu/).\n",
    "\n",
    "\n",
    "### Topics\n",
    "+ Write small, reusable methods\n",
    "+ \n",
    "\n",
    "This notebook contains examples of software problems and their solutions. The examples are taken from student programming assignments written in Python. They have been edited to best illustrate better solution methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write small, reusable methods\n",
    "### Specified feature: ensure that all ids are unique\n",
    "The program reads a set of records from a file, and must ensure that all ids in the records are unique. In particular, an errors must report any duplicated ids.\n",
    "At this point in the code the records have been read and the code has ensured that each record has an id.\n",
    "\n",
    "### Student approach\n",
    "The student program does ensure that all ids are unique, but is overly complex and long because the duplicate detection is integrated into the data loading method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2: id id_3 duplicated \n",
      "4: id id_3 duplicated \n",
      "7: id id_3 duplicated \n",
      "5: id id_6 duplicated \n",
      "6: id id_6 duplicated "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<__main__.Subject at 0x7fe6046ef390>,\n",
       " <__main__.Subject at 0x7fe6046ef438>,\n",
       " <__main__.Subject at 0x7fe6046ef4e0>,\n",
       " <__main__.Subject at 0x7fe6046ef588>,\n",
       " <__main__.Subject at 0x7fe6046ef630>,\n",
       " <__main__.Subject at 0x7fe6046ef6d8>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv, sys\n",
    "\n",
    "class Subject(object):\n",
    "    def __init__(self, id, data):\n",
    "        # error checking here removed from this example\n",
    "        self.id = id\n",
    "        self.data = data\n",
    "\n",
    "    @classmethod\n",
    "    def load_file(cls, file_name):\n",
    "        \"\"\" Load subjects from a tab-separated value file into a list of Subject instances\n",
    "\n",
    "        The file contains a header row. Each following row contains data about one subject.\n",
    "        This method outputs error messages, including a list of duplicate ids.\n",
    "\n",
    "        Args:\n",
    "            file_name (:obj:'str'): path to a file of subjects\n",
    "\n",
    "        Returns:\n",
    "            (:obj:'list'): list of Subject instances formed from subject information in `file_name`\n",
    "        \"\"\"\n",
    "        subjects = []\n",
    "        with open(file_name) as csvfile:\n",
    "            reader = csv.DictReader(csvfile, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                subject = cls(*row.values())\n",
    "                subjects.append(subject)\n",
    "\n",
    "        # detect duplicate subject ids\n",
    "        subject_ids = [subject.id for subject in subjects]\n",
    "        dup_id_row = []\n",
    "        dup_ids = []\n",
    "        for testid in set(subject_ids):\n",
    "            if 1 < subject_ids.count(testid):\n",
    "                for index, value in enumerate(subject_ids):\n",
    "                    if value == testid:\n",
    "                        dup_id_row.append(index + 2)  # + 2 because 1st row (header) are keys and index is zero-based\n",
    "                        dup_ids.append(value)\n",
    "        # duplicate detection done\n",
    "        # dup_ids contains a list of duplicated ids, and dup_id_row contains their corresponding row numbers\n",
    "        errors = []\n",
    "        if dup_ids:\n",
    "            for id, row in zip(dup_ids, dup_id_row):\n",
    "                errors.append(\"{}: id {} duplicated \".format(row, id))\n",
    "        if errors:\n",
    "            sys.stderr.write('\\n'.join(errors))\n",
    "        return subjects\n",
    "\n",
    "def save_test_data(file, data):\n",
    "    with open(subjects_file, 'w') as file:\n",
    "        for element in example_data:\n",
    "            file.write('\\t'.join(element) + '\\n')\n",
    "\n",
    "# create test data\n",
    "example_data = [\n",
    "    ['id', 'data'],\n",
    "    ['id_3', 'data1'],\n",
    "    ['id_4', 'data2'],\n",
    "    ['id_3', 'data3'],\n",
    "    ['id_6', 'data4'],\n",
    "    ['id_6', 'data5'],\n",
    "    ['id_3', 'data5']\n",
    "]\n",
    "subjects_file = 'subjects.tsv'\n",
    "save_test_data(subjects_file, example_data)\n",
    "\n",
    "Subject.load_file(subjects_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with this approach\n",
    "1. 8 lines of code perform duplicate detection, which is a specific problem that is distinct from reading in data and could be written in one, generic solution\n",
    "2. If a generic method for duplicate detection were available, it could be used to detect and report duplicates in other software\n",
    "3. Unnecessarily complex computationally: this approach takes $O(n^{2})$ time, which means that it grows at least as fast as the cube of the number of subjects\n",
    "\n",
    "### Addressing these problems\n",
    "+ Separate the issue of finding duplicates from the issues of reporting them as errors and of determining the rows in which they occur\n",
    "+ Make a method that finds duplicates in a list\n",
    "+ Make the method run fast, in $O(n)$ time\n",
    "+ Use the method to find duplicates in the subjects\n",
    "+ If it finds duplicates, use other data saved with the subjects to report the errors and the rows in which they occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "id id_6 is duplicated \n",
      "id id_3 is duplicated "
     ]
    }
   ],
   "source": [
    "def find_dupes(ids):\n",
    "    # return a set of the duplicates in ids; $O(n)$ complexity\n",
    "    known_ids = set()\n",
    "    duped_ids = set()\n",
    "    for id in ids:\n",
    "        if id in known_ids:\n",
    "            duped_ids.add(id)\n",
    "        known_ids.add(id)\n",
    "    return duped_ids\n",
    "\n",
    "# test find_dupes\n",
    "assert find_dupes([1, 2, 1, 3]) == {1}\n",
    "assert find_dupes([2, 1, 3]) == set()\n",
    "\n",
    "class Subject(object):\n",
    "    def __init__(self, id, data):\n",
    "        # error checking here removed from this example\n",
    "        self.id = id\n",
    "        self.data = data\n",
    "\n",
    "    @staticmethod\n",
    "    def get_duped_subjects(subjects):\n",
    "        # detect duplicate subject ids\n",
    "        subject_ids = [subject.id for subject in subjects]\n",
    "        duped_subject_ids = find_dupes(subject_ids)\n",
    "        errors = []\n",
    "        if duped_subject_ids:\n",
    "            for id in duped_subject_ids:\n",
    "                errors.append(\"id {} is duplicated \".format(id))\n",
    "        return errors\n",
    "\n",
    "    @classmethod\n",
    "    def load_file(cls, file_name):\n",
    "        \"\"\" Load subjects from a tab-separated value file into a list of Subject instances\n",
    "        \"\"\"\n",
    "        subjects = []\n",
    "        with open(file_name) as csvfile:\n",
    "            reader = csv.DictReader(csvfile, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                subject = cls(*row.values())\n",
    "                subjects.append(subject)\n",
    "        errors = Subject.get_duped_subjects(subjects)\n",
    "        if errors:\n",
    "            sys.stderr.write('\\n'.join(errors))\n",
    "        return subjects\n",
    "\n",
    "subjects = Subject.load_file(subjects_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits of this approach\n",
    "1. We wrote a fast, simple, reusable generic method for duplicate detection. It takes $O(n)$ time, which is optimal.\n",
    "2. It takes only 9 lines of code, and is tested a little.\n",
    "\n",
    "### Problems with this approach\n",
    "1. The row numbers of duplicated subject ids aren't reported.\n",
    "\n",
    "### Addressing this problem\n",
    "+ Save and use the row numbers of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2: id id_3 is duplicated \n",
      "4: id id_3 is duplicated \n",
      "5: id id_6 is duplicated \n",
      "6: id id_6 is duplicated \n",
      "7: id id_3 is duplicated "
     ]
    }
   ],
   "source": [
    "class Subject(object):\n",
    "\n",
    "    def __init__(self, id, data, row_num): # CHANGED\n",
    "        # error checking here removed from this example\n",
    "        self.id = id\n",
    "        self.data = data\n",
    "        self._row_num = row_num # CHANGED\n",
    "\n",
    "    @staticmethod\n",
    "    def get_duped_subjects(subjects):\n",
    "        # detect duplicate subject ids\n",
    "        subject_ids = [subject.id for subject in subjects]\n",
    "        duped_subject_ids = find_dupes(subject_ids)\n",
    "        errors = []\n",
    "        if duped_subject_ids:\n",
    "             # START CHANGED\n",
    "            for subject in subjects:\n",
    "                if subject.id in duped_subject_ids:\n",
    "                    errors.append(\"{}: id {} is duplicated \".format(subject._row_num, subject.id))\n",
    "             # END CHANGED\n",
    "        return errors\n",
    "\n",
    "    @classmethod\n",
    "    def load_file(cls, file_name):\n",
    "        \"\"\" Load subjects from a tab-separated value file into a list of Subject instances\n",
    "        \"\"\"\n",
    "        subjects = []\n",
    "        row_num = 2 # CHANGED\n",
    "        with open(file_name) as csvfile:\n",
    "            reader = csv.DictReader(csvfile, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                subject = cls(*row.values(), row_num) # CHANGED\n",
    "                subjects.append(subject)\n",
    "                row_num += 1 # CHANGED\n",
    "        errors = Subject.get_duped_subjects(subjects)\n",
    "        if errors:\n",
    "            sys.stderr.write('\\n'.join(errors))\n",
    "        return subjects\n",
    "\n",
    "subjects = Subject.load_file(subjects_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final remarks\n",
    "1. Duplicated ids are reported in row order\n",
    "2. We have a reusable duplicate detection method\n",
    "3. We should think about where this method belongs\n",
    "4. Subjects store their row numbers, which may be handy for other purposes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
